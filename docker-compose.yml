services:
  trellis2:
    build:
      context: .
      args:
        # TORCH_CUDA_ARCH_LIST maps NVIDIA GPU generations to compute capabilities:
        # - A100: 8.0
        # - 3090/3080: 8.6
        # - 4090: 8.9
        # - H100: 9.0
        # Use a semicolon-separated list to build multiple SMs (e.g., "8.6;9.0").
        TORCH_CUDA_ARCH_LIST: "8.9"
        MAX_JOBS: "1"
    ports:
      - "7860:7860"
    environment:
      GRADIO_SERVER_NAME: 0.0.0.0
      GRADIO_SERVER_PORT: 7860
      HF_HOME: /root/.cache/huggingface
      CUDA_HOME: /usr/local/cuda
      ATTN_BACKEND: flash_attn
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,utility
    volumes:
      - hf_cache:/root/.cache/huggingface
    runtime: nvidia
    shm_size: "8g"

volumes:
  hf_cache:
